#离线模型训练-工作流程
##离线模型训练，分为以下几个步骤： 0.源表采样；//根据具体场景决定是否需要该步骤；本例中, 不采样，AUC为0.68；采样后，AUC为0.7。 1.样本生成； 2.模型训练； 3.模型评估； 4.特征权重评估；
接下来，我们以微博相机为例，来详述离线模型训练的工作流程：
注：例子中的工作环境为信息系统部10.77.16.104
###0.源表采样 - 工作目录：/data0/work_space/weimining/hive/mis2/shell/strategy/feed_wbcamera_ctr/ 源表采样，依赖于以下几个步骤： ####1）创建采样表 创建与源表Schema完全一致的采样表；如在本例中，源表为camerafeed_ctr_feature_all_v4，根据该源表Schema，创建采样表camerafeed_ctr_feature_all_v4_sampling，建表语句参考：create_sample_table_for_v4.hql
####2）采样脚本 编辑采样脚本，用于从源表中对正负样本按照1:10比例进行采样，并将采样结果插入到采样表，采样脚本参考：camerafeed_ctr_feature_all_v4_sampling_add_partition.sh
采样脚本准备好后，根据采样分区的个数，可以编写shell脚本来对目标分区进行采样，shell脚本示例参考：sampling_for_camera_v4.sh，对2016年6月份的数据进行采样。
###1.样本生成 - 工作目录：/data1/work/datasys/weispark/runtime/mis2/ctr/sample 样本生成，依赖于以下几个环节： ####1）特征元数据文件data.conf 首先准备好要提取特征的表，如本例中为camerafeed_ctr_feature_all_v4_sampling，然后执行create_data_conf.sh [table_name]，在我们的例子中，是create_data_conf.sh camerafeed_ctr_feature_all_v4_sampling；执行成功后，会在当前目录下生产文件camerafeed_ctr_feature_all_v4.data.conf，该文件是特征元数据文件，文件内容格式为"序号@字段名字"，这里的字段名字也即是特征名字，我们需要根据特征的取舍、特征的类型来手动修改该文件。特征的取舍指的是该特征在模型训练中是否保留，如不需要，则注释掉；特征的类型包含以下几类：bool,enum,origin,persist；bool表示布尔值，enum代表枚举类型(需要指定operator函数，详见下文)，也即把连续数据离散化; origin代表原值(源数据范围在0-1之间的特征可取原值类型);persist代表保留值，主要用来标记label。除了特征的类型，我们还要在文件开头指定label的类型，label有两种类型：flag和repeat；flag表示所见即所得，repeat表示需要进一步将文件展开才能获取到最终的label值。 data.conf示例参见：camerafeed_ctr_feature_all_v4.data.conf
关于data.conf文件说明： data.conf文件生成后，需要我们手动来修改，因此在这里特别说明一下。 1）index@name@map-type@operator@args 其中index@name是通过脚本自动生成的，我们需要关心的是map-type、operator和args。map-type也即前面提到的bool，enum，origin，persist，4种类型，四种类型的解释如上所示。如果map-type为enum类型，我们需要指定operator操作符函数，目前支持的函数有：
hour函数：取小时
week函数：取周数
minute函数：取分钟
log函数：以2为底取对数；
log10函数：以10为底取对数；
piece函数：取截断 大多数函数都不需要参数，即args，piece函数是个例外，需要指定参数，参数示例，见camerafeed_ctr_feature_all_v4.data.conf中的piece函数示例。 2) 关于operator的种类和实现细节，大家可以参考： http://git.intra.weibo.com/datastrategy/spark/tree/master/project/java/datamapper/src/main/java/cn/sina/operator 如有新的operator函数需要实现、添加，请联系刘博。
####2）特征映射文件feature.conf 在前一步执行create_data_conf.sh [table_name]后，还会在feature_conf_dir/生成与表名一致的特征文件夹，本例中为feature_conf_dir/camerafeed_ctr_feature_all_v4，该特征文件夹下面有若干特征文件，文件内容为空，文件个数与特征个数一致。我们需要根据特征值的特点和运算逻辑，手工编辑其中的每一个特征文件，在步骤1）中抛弃的特征可以不用编辑。旧特征的文件内容可以参考以前的内容，新的特征，需要根据经验判断或者通过查取Hive表该字段范围来进行填写。本例中，请参考feature_conf_dir/camerafeed_ctr_feature_all_v4下面的内容； 以上内容准备好后，执行bin/GenFeatureConf 来生产feature.conf文件,其中data_conf_file就是步骤1）中生成的data.conf文件，feature_file_dir即是步骤2）中自动生成的feature_conf_dir/camerafeed_ctr_feature_all_v4目录，feature_conf_file为即将生成的目标feature.conf文件，在本例中，是camerafeed_ctr_feature_all_v4.feature.conf。
####3）conf文件上传HDFS 将步骤1）、2）生成的data.conf和feature.conf分别上传到HDFS，用于后面的配置文件；
####4）样本生成配置文件 在generate_instances.env目录下，新建样本生成配置文件，文件内容主要包含： data_conf: data.conf的HDFS路径 feature_conf: feature.conf的HDFS路径 src_data_store_path: 表数据HDFS路径 des_data_store_path: 样本路径 partition: 任务分区数
样本配置文件内容可参考：generate_instances.env/camerafeed_ctr_v4
####5）生成样本脚本 本例中的生成样本脚本为run_instances.sh，主要作用是调用了同目录下的generate_instances.sh执行文件，传入配置文件等参数。执行生成样本脚本，即可在配置文件中指定的des_data_store_path样本路径中，生成样本内容,作为后面模型训练的输入。
###2.模型训练 - 工作目录：/data1/work/datasys/weispark/runtime/mis2/ctr/train_spark 模型训练，依赖于以下一些环节： ####1）模型训练配置文件 在train.env文件夹下，新建模型训练配置文件，本例中为train.env/camerafeed_ctr_feature_mapping_v1_4.train.sh，文件主要包含： trainpath:样本文件路径，也即样本生成步骤4）中的des_data_store_path路径； MODEL_FILE：模型存储路径，也即模型训练成功完成后，模型的存储路径； FEATURES：特征的数量，本例中为21；
####2) 模型训练脚本 编写shell脚本（本例中为run_camera_train.sh）来调用train.sh模型训练脚本，主要在shell脚本中传入1）中的配置文件路径；在train.sh中，主要是通过Spark来运行lr-algorithm_2.10-0.1-SNAPSHOT.jar中的应用，通过执行LR来对模型进行训练，训练成功后，会将成功训练的模型存储在1）中配置的MODEL_FILE路径下。
###3.模型评估 - 工作目录：/data1/work/datasys/weispark/runtime/mis2/ctr/evaluate_spark 模型评估，依赖于以下一些环节： ####1）模型评估配置文件 在evaluate.env/目录下，新建模型评估配置文件(本例中为camerafeed_ctr_feature_mapping_v1_4.eva)，文件内容主要包括： pre_inputData:用于预测和评估的样本文件，这里可以和之前的训练数据一样，也可以是测试数据集，如果是测试数据集，需要根据步骤1.样本生成重新生成测试数据的样本数据，然后将样本数据的路径指定在这里； pre_outputPrefix：存储预测的结果的HDFS中间路径； pre_modelPath：模型存储路径，也即步骤2.模型训练中的MODEL_FILE路径 FEATURES: 指定为-1即可。
####2）模型预测和评估 通过编写shell脚本（本例中为run_camera_eva_wulei3.sh）来调用evaluate.sh执行脚本，值得一提的是，需要先预测，再进行评估，所以shell脚本中，需要先调用PREDICT模式，再调用EVA模式; evaluate.sh执行脚本主要是调用了lr-algorithm_2.10-0.1-SNAPSHOT.jar应用中预测和评估的部分。
成功执行PREDICT模式和EVA模式后，会在log文件夹生成两个文件，.predict和.eva，其中.eva包含了预测的准确率和AUC, 通过以下命令来查看两个评估指标的具体值： grep -i 'area under ROC' log/table_name.eva.date grep -i 'precision' log/table_name.eva.date 如果两条命令没有任何输出结果，请检查log内容，查看任务是否执行失败，并查找失败原因。
###4.特征权重评估 - 工作目录：/data1/work/datasys/weispark/runtime/mis2/ctr/evaluate_spark/model 特征权重评估，需要依赖如下一些环节： ####1）将相关文件下载到本地 将模型文件，也即2.模型训练中的MODEL_FILE通过hdfs getmerge到本地data文件夹下；将feature.conf文件通过hdfs getmerge到本地data文件夹下； 在data文件夹下，创建dict字典文件，字典文件内容为“特征名称 分隔符 特征解释”,该文件的主要作用是为了输出文件的可读性；示例可参考：data/camerafeed_ctr_feature_all_v4.dict.txt；
####2）更新特征权重评估脚本parse_map.py，更新如下字段： map_file：feature.conf文件路径； model_file：模型文件路径； feature_dict_fn：字典文件路径，也即1）中提及的字典文件； 执行命令 python parse_map.py，命令执行成功，会在data目录下生产：camerafeed_ctr_feature_sample_v1_4.model.20160705.map.txt，该文件中记录了特征：特征值：权重等重要信息，通过将该文件导入到Excel等工具，可以对新增加的特征权重进行查看，结合AUC的变化确认新特征的加入是否有效。
--End