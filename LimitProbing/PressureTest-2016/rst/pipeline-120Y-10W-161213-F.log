spark-submit --jars /data0/work_space/service/spark-2.0.0-bin-hadoop2.4/jars/hadoop-lzo-0.4.15.jar --master yarn --deploy-mode client --num-executors 100 --driver-memory 7g --executor-cores 4 --executor-memory 7g --class com.weibo.datasys.pipeline.Runner weispark-ml-0.5.0-SNAPSHOT.jar pipeline.xml [5]
Running pipeline: ML training: Resources Limit Probing

16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694589 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694590 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694591 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694592 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694593 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694594 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694595 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694596 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694597 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694598 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694599 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694600 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694601 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694602 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694603 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694604 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694605 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694606 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694607 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694608 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694609 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694610 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694611 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694612 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694613 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694614 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694615 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694616 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694617 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694618 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694619 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694620 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694621 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694622 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694623 tasks (1024.1 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694624 tasks (1024.1 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694625 tasks (1024.1 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:48 ERROR TaskSetManager: Total size of serialized results of 694626 tasks (1024.1 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Total size of serialized results of 694589 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1934)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:983)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.reduce(RDD.scala:965)
	at org.apache.spark.sql.Dataset.reduce(Dataset.scala:1264)
	at com.weibo.datasys.common.HDFSFileLoader$.loadFile(HDFSFileLoader.scala:44)
	at com.weibo.datasys.common.HDFSFileLoader$.loadLibsvmHDFS(HDFSFileLoader.scala:14)
	at com.weibo.datasys.algorithms.LogisticRegressionWithLBFGS$.run(LogisticRegressionWithLBFGS.scala:35)
	at com.weibo.datasys.pipeline.MLConfig$$anonfun$run$1.apply(MLConfig.scala:35)
	at com.weibo.datasys.pipeline.MLConfig$$anonfun$run$1.apply(MLConfig.scala:29)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at com.weibo.datasys.pipeline.MLConfig.run(MLConfig.scala:29)
	at com.weibo.datasys.pipeline.Framework$$anonfun$runJob$2.apply(Framework.scala:25)
	at com.weibo.datasys.pipeline.Framework$$anonfun$runJob$2.apply(Framework.scala:23)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at com.weibo.datasys.pipeline.Framework$.runJob(Framework.scala:23)
	at com.weibo.datasys.pipeline.Runner$.main(Runner.scala:26)
	at com.weibo.datasys.pipeline.Runner.main(Runner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
16/12/13 08:35:49 ERROR TaskSetManager: Total size of serialized results of 694627 tasks (1024.1 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)
16/12/13 08:35:49 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(106,WrappedArray((694999,1,0,Vector(AccumulableInfo(6648,Some(internal.metrics.executorDeserializeTime),Some(0),None,true,true,None), AccumulableInfo(6649,Some(internal.metrics.executorRunTime),Some(0),None,true,true,None), AccumulableInfo(6650,Some(internal.metrics.resultSize),Some(0),None,true,true,None), AccumulableInfo(6651,Some(internal.metrics.jvmGCTime),Some(287),None,true,true,None), AccumulableInfo(6652,Some(internal.metrics.resultSerializationTime),Some(0),None,true,true,None), AccumulableInfo(6653,Some(internal.metrics.memoryBytesSpilled),Some(0),None,true,true,None), AccumulableInfo(6654,Some(internal.metrics.diskBytesSpilled),Some(0),None,true,true,None), AccumulableInfo(6655,Some(internal.metrics.peakExecutionMemory),Some(0),None,true,true,None), AccumulableInfo(6656,Some(internal.metrics.updatedBlockStatuses),Some(ArrayBuffer()),None,true,true,None), AccumulableInfo(6657,Some(internal.metrics.shuffle.read.remoteBlocksFetched),Some(0),None,true,true,None), AccumulableInfo(6658,Some(internal.metrics.shuffle.read.localBlocksFetched),Some(0),None,true,true,None), AccumulableInfo(6659,Some(internal.metrics.shuffle.read.remoteBytesRead),Some(0),None,true,true,None), AccumulableInfo(6660,Some(internal.metrics.shuffle.read.localBytesRead),Some(0),None,true,true,None), AccumulableInfo(6661,Some(internal.metrics.shuffle.read.fetchWaitTime),Some(0),None,true,true,None), AccumulableInfo(6662,Some(internal.metrics.shuffle.read.recordsRead),Some(0),None,true,true,None), AccumulableInfo(6663,Some(internal.metrics.shuffle.write.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(6664,Some(internal.metrics.shuffle.write.recordsWritten),Some(0),None,true,true,None), AccumulableInfo(6665,Some(internal.metrics.shuffle.write.writeTime),Some(0),None,true,true,None), AccumulableInfo(6666,Some(internal.metrics.input.bytesRead),Some(0),None,true,true,None), AccumulableInfo(6667,Some(internal.metrics.input.recordsRead),Some(11021),None,true,true,None), AccumulableInfo(6668,Some(internal.metrics.output.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(6669,Some(internal.metrics.output.recordsWritten),Some(0),None,true,true,None), AccumulableInfo(6647,Some(duration total (min, med, max)),Some(-1),None,true,true,Some(sql)), AccumulableInfo(6644,Some(number of output rows),Some(11021),None,true,true,Some(sql)), AccumulableInfo(6645,Some(number of output rows),Some(11021),None,true,true,Some(sql)), AccumulableInfo(6646,Some(number of output rows),Some(11020),None,true,true,Some(sql)))), (695264,1,0,Vector(AccumulableInfo(6648,Some(internal.metrics.executorDeserializeTime),Some(0),None,true,true,None), AccumulableInfo(6649,Some(internal.metrics.executorRunTime),Some(0),None,true,true,None), AccumulableInfo(6650,Some(internal.metrics.resultSize),Some(0),None,true,true,None), AccumulableInfo(6651,Some(internal.metrics.jvmGCTime),Some(45),None,true,true,None), AccumulableInfo(6652,Some(internal.metrics.resultSerializationTime),Some(0),None,true,true,None), AccumulableInfo(6653,Some(internal.metrics.memoryBytesSpilled),Some(0),None,true,true,None), AccumulableInfo(6654,Some(internal.metrics.diskBytesSpilled),Some(0),None,true,true,None), AccumulableInfo(6655,Some(internal.metrics.peakExecutionMemory),Some(0),None,true,true,None), AccumulableInfo(6656,Some(internal.metrics.updatedBlockStatuses),Some(ArrayBuffer()),None,true,true,None), AccumulableInfo(6657,Some(internal.metrics.shuffle.read.remoteBlocksFetched),Some(0),None,true,true,None), AccumulableInfo(6658,Some(internal.metrics.shuffle.read.localBlocksFetched),Some(0),None,true,true,None), AccumulableInfo(6659,Some(internal.metrics.shuffle.read.remoteBytesRead),Some(0),None,true,true,None), AccumulableInfo(6660,Some(internal.metrics.shuffle.read.localBytesRead),Some(0),None,true,true,None), AccumulableInfo(6661,Some(internal.metrics.shuffle.read.fetchWaitTime),Some(0),None,true,true,None), AccumulableInfo(6662,Some(internal.metrics.shuffle.read.recordsRead),Some(0),None,true,true,None), AccumulableInfo(6663,Some(internal.metrics.shuffle.write.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(6664,Some(internal.metrics.shuffle.write.recordsWritten),Some(0),None,true,true,None), AccumulableInfo(6665,Some(internal.metrics.shuffle.write.writeTime),Some(0),None,true,true,None), AccumulableInfo(6666,Some(internal.metrics.input.bytesRead),Some(0),None,true,true,None), AccumulableInfo(6667,Some(internal.metrics.input.recordsRead),Some(3593),None,true,true,None), AccumulableInfo(6668,Some(internal.metrics.output.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(6669,Some(internal.metrics.output.recordsWritten),Some(0),None,true,true,None), AccumulableInfo(6647,Some(duration total (min, med, max)),Some(-1),None,true,true,Some(sql)), AccumulableInfo(6644,Some(number of output rows),Some(3593),None,true,true,Some(sql)), AccumulableInfo(6645,Some(number of output rows),Some(3593),None,true,true,Some(sql)), AccumulableInfo(6646,Some(number of output rows),Some(3592),None,true,true,Some(sql)))), (695274,1,0,Vector(AccumulableInfo(6648,Some(internal.metrics.executorDeserializeTime),Some(0),None,true,true,None), AccumulableInfo(6649,Some(internal.metrics.executorRunTime),Some(0),None,true,true,None), AccumulableInfo(6650,Some(internal.metrics.resultSize),Some(0),None,true,true,None), AccumulableInfo(6651,Some(internal.metrics.jvmGCTime),Some(41),None,true,true,None), AccumulableInfo(6652,Some(internal.metrics.resultSerializationTime),Some(0),None,true,true,None), AccumulableInfo(6653,Some(internal.metrics.memoryBytesSpilled),Some(0),None,true,true,None), AccumulableInfo(6654,Some(internal.metrics.diskBytesSpilled),Some(0),None,true,true,None), AccumulableInfo(6655,Some(internal.metrics.peakExecutionMemory),Some(0),None,true,true,None), AccumulableInfo(6656,Some(internal.metrics.updatedBlockStatuses),Some(ArrayBuffer()),None,true,true,None), AccumulableInfo(6657,Some(internal.metrics.shuffle.read.remoteBlocksFetched),Some(0),None,true,true,None), AccumulableInfo(6658,Some(internal.metrics.shuffle.read.localBlocksFetched),Some(0),None,true,true,None), AccumulableInfo(6659,Some(internal.metrics.shuffle.read.remoteBytesRead),Some(0),None,true,true,None), AccumulableInfo(6660,Some(internal.metrics.shuffle.read.localBytesRead),Some(0),None,true,true,None), AccumulableInfo(6661,Some(internal.metrics.shuffle.read.fetchWaitTime),Some(0),None,true,true,None), AccumulableInfo(6662,Some(internal.metrics.shuffle.read.recordsRead),Some(0),None,true,true,None), AccumulableInfo(6663,Some(internal.metrics.shuffle.write.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(6664,Some(internal.metrics.shuffle.write.recordsWritten),Some(0),None,true,true,None), AccumulableInfo(6665,Some(internal.metrics.shuffle.write.writeTime),Some(0),None,true,true,None), AccumulableInfo(6666,Some(internal.metrics.input.bytesRead),Some(0),None,true,true,None), AccumulableInfo(6667,Some(internal.metrics.input.recordsRead),Some(3045),None,true,true,None), AccumulableInfo(6668,Some(internal.metrics.output.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(6669,Some(internal.metrics.output.recordsWritten),Some(0),None,true,true,None), AccumulableInfo(6647,Some(duration total (min, med, max)),Some(-1),None,true,true,Some(sql)), AccumulableInfo(6644,Some(number of output rows),Some(3045),None,true,true,Some(sql)), AccumulableInfo(6645,Some(number of output rows),Some(3045),None,true,true,Some(sql)), AccumulableInfo(6646,Some(number of output rows),Some(3044),None,true,true,Some(sql)))), (694793,1,0,Vector(AccumulableInfo(6648,Some(internal.metrics.executorDeserializeTime),Some(0),None,true,true,None), AccumulableInfo(6649,Some(internal.metrics.executorRunTime),Some(0),None,true,true,None), AccumulableInfo(6650,Some(internal.metrics.resultSize),Some(0),None,true,true,None), AccumulableInfo(6651,Some(internal.metrics.jvmGCTime),Some(436),None,true,true,None), AccumulableInfo(6652,Some(internal.metrics.resultSerializationTime),Some(0),None,true,true,None), AccumulableInfo(6653,Some(internal.metrics.memoryBytesSpilled),Some(0),None,true,true,None), AccumulableInfo(6654,Some(internal.metrics.diskBytesSpilled),Some(0),None,true,true,None), AccumulableInfo(6655,Some(internal.metrics.peakExecutionMemory),Some(0),None,true,true,None), AccumulableInfo(6656,Some(internal.metrics.updatedBlockStatuses),Some(ArrayBuffer()),None,true,true,None), AccumulableInfo(6657,Some(internal.metrics.shuffle.read.remoteBlocksFetched),Some(0),None,true,true,None), AccumulableInfo(6658,Some(internal.metrics.shuffle.read.localBlocksFetched),Some(0),None,true,true,None), AccumulableInfo(6659,Some(internal.metrics.shuffle.read.remoteBytesRead),Some(0),None,true,true,None), AccumulableInfo(6660,Some(internal.metrics.shuffle.read.localBytesRead),Some(0),None,true,true,None), AccumulableInfo(6661,Some(internal.metrics.shuffle.read.fetchWaitTime),Some(0),None,true,true,None), AccumulableInfo(6662,Some(internal.metrics.shuffle.read.recordsRead),Some(0),None,true,true,None), AccumulableInfo(6663,Some(internal.metrics.shuffle.write.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(6664,Some(internal.metrics.shuffle.write.recordsWritten),Some(0),None,true,true,None), AccumulableInfo(6665,Some(internal.metrics.shuffle.write.writeTime),Some(0),None,true,true,None), AccumulableInfo(6666,Some(internal.metrics.input.bytesRead),Some(0),None,true,true,None), AccumulableInfo(6667,Some(internal.metrics.input.recordsRead),Some(14262),None,true,true,None), AccumulableInfo(6668,Some(internal.metrics.output.bytesWritten),Some(0),None,true,true,None), AccumulableInfo(6669,Some(internal.metrics.output.recordsWritten),Some(0),None,true,true,None), AccumulableInfo(6647,Some(duration total (min, med, max)),Some(-1),None,true,true,Some(sql)), AccumulableInfo(6644,Some(number of output rows),Some(14262),None,true,true,Some(sql)), AccumulableInfo(6645,Some(number of output rows),Some(14261),None,true,true,Some(sql)), AccumulableInfo(6646,Some(number of output rows),Some(14261),None,true,true,Some(sql))))))
16/12/13 08:35:49 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:152)
	at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:132)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:571)
	at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:179)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:108)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:119)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:724)
16/12/13 08:35:49 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:152)
	at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:132)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:571)
	at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:179)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:108)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:119)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:724)
16/12/13 08:35:49 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:152)
	at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:132)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:571)
	at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:179)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:108)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:119)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:724)
16/12/13 08:35:49 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:152)
	at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:132)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:571)
	at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:179)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:108)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:119)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:724)
16/12/13 08:35:50 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:152)
	at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:132)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:571)
	at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:179)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:108)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:119)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:724)
16/12/13 08:35:50 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:152)
	at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:132)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:571)
	at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:179)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:108)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:119)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:724)
16/12/13 08:35:50 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:152)
	at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:132)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:571)
	at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:179)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:108)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:119)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:724)
16/12/13 08:35:50 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:152)
	at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:132)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:571)
	at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:179)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:108)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:119)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:724)
16/12/13 08:35:50 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:152)
	at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:132)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:571)
	at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:179)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:108)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:119)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:724)
